{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1d01c8e-b4ed-4742-b83c-211671ddd106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60ee2aa4-72a6-43fb-9646-7bf989aa08d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfcl.models.ptavit3dca.ptavit3dca_dn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bd1c127-fc3e-4068-be53-c0269dec42ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Using stem normalization \n",
      " @@@@@@@@@@@@@ Going DOWN @@@@@@@@@@@@@@@@@@@ \n",
      "depth:= 0, layer_dim_in: 96, layer_dim: 96, stage_depth::2, spatial_size::(32, 32), scales::[16, 8, 8]\n",
      "depth:= 1, layer_dim_in: 96, layer_dim: 192, stage_depth::2, spatial_size::(16, 16), scales::[32, 4, 4]\n",
      "depth:= 2, layer_dim_in: 192, layer_dim: 384, stage_depth::5, spatial_size::(8, 8), scales::[64, 2, 2]\n",
      "depth:= 3, layer_dim_in: 384, layer_dim: 768, stage_depth::2, spatial_size::(4, 4), scales::[128, 1, 1]\n",
      " XXXXXXXXXXXXXXXXXXXXX Coming up XXXXXXXXXXXXXXXXXXXXXXXXX \n",
      "depth:= 4, layer_dim_in: 384, layer_dim: 384, stage_depth::5, spatial_size::(8, 8), scales::[64, 2, 2]\n",
      "depth:= 5, layer_dim_in: 192, layer_dim: 192, stage_depth::2, spatial_size::(16, 16), scales::[32, 4, 4]\n",
      "depth:= 6, layer_dim_in: 96, layer_dim: 96, stage_depth::2, spatial_size::(32, 32), scales::[16, 8, 8]\n"
     ]
    }
   ],
   "source": [
    "NClasses=2 #                                                       \n",
    "nf=96                                                              \n",
    "verbose = True  # print only on global_rank==0     \n",
    "model_config = {'in_channels_s2':4,\n",
    "                'in_channels_s1':5,\n",
    "               'spatial_size_init':(128,128),                      \n",
    "               'depths':[2,2,5,2],                                 \n",
    "               'nfilters_init':nf,                                 \n",
    "               'nheads_start':nf//4,                               \n",
    "               'NClasses':NClasses,                                \n",
    "               'verbose':verbose,                                  \n",
    "               'segm_act':'sigmoid'}                               \n",
    "                                                                   \n",
    "# UNet-like model                                                  \n",
    "model = ptavit3dca_dn(**model_config) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18f7c3ce-63c4-412f-a519-3206e3f0fb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depending on Hardware, reduce spatial size to run on demo. Tested on cpu with 32GB of memory\n",
    "# Random 3D input batch size of 2, 5 s1 channels, 4 s2 channels, 4 time instances, height x width = 64 x 64\n",
    "b,c1,c2,t,h,w = 2,5,4,4,128,128\n",
    "ins1 = torch.rand(b,c1,t,h,w)\n",
    "ins2 = torch.rand(b,c2,t,h,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ad23a00-0b07-4e35-ab3b-68bea5c6ba02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape S2::torch.Size([2, 4, 4, 128, 128]), shape S1::torch.Size([2, 5, 4, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "print(\"input shape S2::{}, shape S1::{}\".format(ins2.shape,ins1.shape))\n",
    "outs = model(ins2,ins1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b335ad8-3414-465a-8fc9-d81104a11801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 128, 128])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8b0b8fc-aeab-44a4-883e-98902da7af10",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_e = outs[:,:NClasses]\n",
    "preds_b = outs[:,NClasses:2*NClasses]\n",
    "preds_d = outs[:,2*NClasses:3*NClasses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd8219fa-dc56-4ec9-adf1-4bcb988b7fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extent shape::torch.Size([2, 2, 128, 128])\n",
      "bounds shape::torch.Size([2, 2, 128, 128])\n",
      "distance shape::torch.Size([2, 2, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "print(\"extent shape::{}\".format(preds_e.shape))\n",
    "print(\"bounds shape::{}\".format(preds_b.shape))\n",
    "print(\"distance shape::{}\".format(preds_d.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2956f09c-6580-471e-ad3a-457df00d7420",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
